{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawception Reactions\n",
    "\n",
    "This Notebook will create models to predict the number of reactions a Drawception image will recieve. There are 5 reactions an image can recieve and each one will need a different model. I will also make a prediction model of total reactions an image recieves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data\n",
    "drawception = pd.read_csv('drawception_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a total reactions feature\n",
    "drawception['REACT'] = drawception['LIKE']+drawception['HAHA']+drawception['WOW']+drawception['LOVE']+drawception['DUCK']\n",
    "\n",
    "# Add image path column\n",
    "drawception['img_path'] = ['/'.join(drawception.iloc[index,2].split('/')[3:6]) for index in range(len(drawception))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_caption</th>\n",
       "      <th>post_caption</th>\n",
       "      <th>image_url</th>\n",
       "      <th>author</th>\n",
       "      <th>panel_number</th>\n",
       "      <th>LIKE</th>\n",
       "      <th>HAHA</th>\n",
       "      <th>WOW</th>\n",
       "      <th>LOVE</th>\n",
       "      <th>DUCK</th>\n",
       "      <th>game_url</th>\n",
       "      <th>player_num</th>\n",
       "      <th>game_date</th>\n",
       "      <th>game_tags</th>\n",
       "      <th>REACT</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guitar</td>\n",
       "      <td>brown guitar</td>\n",
       "      <td>https://cdn.drawception.com/drawings/1032692/1...</td>\n",
       "      <td>Alexyeaheyaha</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/game/YC8aMef8Ox/guitar/</td>\n",
       "      <td>12</td>\n",
       "      <td>December 18th, 2020</td>\n",
       "      <td>['blitz mode']</td>\n",
       "      <td>0</td>\n",
       "      <td>drawings/1032692/1KqoCkwSjF.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brown guitar</td>\n",
       "      <td>Guitar</td>\n",
       "      <td>https://cdn.drawception.com/drawings/1041492/c...</td>\n",
       "      <td>celemon</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/game/YC8aMef8Ox/guitar/</td>\n",
       "      <td>12</td>\n",
       "      <td>December 18th, 2020</td>\n",
       "      <td>['blitz mode']</td>\n",
       "      <td>0</td>\n",
       "      <td>drawings/1041492/ct5kbWktZ9.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guitar</td>\n",
       "      <td>acoustic guitar</td>\n",
       "      <td>https://cdn.drawception.com/drawings/681336/dz...</td>\n",
       "      <td>Sarramiah and Daughter</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/game/YC8aMef8Ox/guitar/</td>\n",
       "      <td>12</td>\n",
       "      <td>December 18th, 2020</td>\n",
       "      <td>['blitz mode']</td>\n",
       "      <td>0</td>\n",
       "      <td>drawings/681336/dzq8daFSvo.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pre_caption     post_caption  \\\n",
       "0        Guitar     brown guitar   \n",
       "1  brown guitar           Guitar   \n",
       "2        Guitar  acoustic guitar   \n",
       "\n",
       "                                           image_url                  author  \\\n",
       "0  https://cdn.drawception.com/drawings/1032692/1...           Alexyeaheyaha   \n",
       "1  https://cdn.drawception.com/drawings/1041492/c...                 celemon   \n",
       "2  https://cdn.drawception.com/drawings/681336/dz...  Sarramiah and Daughter   \n",
       "\n",
       "   panel_number  LIKE  HAHA  WOW  LOVE  DUCK                  game_url  \\\n",
       "0             2     0     0    0     0     0  /game/YC8aMef8Ox/guitar/   \n",
       "1             4     0     0    0     0     0  /game/YC8aMef8Ox/guitar/   \n",
       "2             6     0     0    0     0     0  /game/YC8aMef8Ox/guitar/   \n",
       "\n",
       "   player_num            game_date       game_tags  REACT  \\\n",
       "0          12  December 18th, 2020  ['blitz mode']      0   \n",
       "1          12  December 18th, 2020  ['blitz mode']      0   \n",
       "2          12  December 18th, 2020  ['blitz mode']      0   \n",
       "\n",
       "                          img_path  \n",
       "0  drawings/1032692/1KqoCkwSjF.png  \n",
       "1  drawings/1041492/ct5kbWktZ9.png  \n",
       "2   drawings/681336/dzq8daFSvo.png  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drawception.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator assistance provided by wiki.python.org\n",
    "\n",
    "# The iloc call is looking for img_path and is using 15 for that index right now\n",
    "def image_batch_gen(dataframe, batch_size, end):   \n",
    "    count = 0\n",
    "    while(1):\n",
    "        image_batch = np.empty((batch_size, 250, 300, 3))\n",
    "        label_batch = np.empty(batch_size)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            my_image = PIL.Image.open(dataframe.iloc[count,15])\n",
    "            my_image = my_image.reduce(2)\n",
    "            \n",
    "            image_batch[i,:,:,:] = np.asarray(my_image)\n",
    "            label_batch[i] = drawception.iloc[count, 14]\n",
    "            \n",
    "            count += 1\n",
    "            if count < end:\n",
    "                count = 0\n",
    "        yield image_batch, label_batch        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split the DF\n",
    "# thanks to Andy Hayden on stack exchange\n",
    "split = np.random.rand(len(drawception)) < 0.8\n",
    "\n",
    "train_df = drawception[split]\n",
    "test_df = drawception[~split]\n",
    "\n",
    "y_train = train_df['REACT']\n",
    "y_test = test_df['REACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30308, 16)    30308\n",
      "(7750, 16)    7750\n"
     ]
    }
   ],
   "source": [
    "# Check that the data is split\n",
    "print(train_df.shape, '  ', len(y_train))\n",
    "print(test_df.shape, '  ', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "# Add a convolutional layer.\n",
    "cnn_model.add(Conv2D(\n",
    "            filters=128,  # number of filters\n",
    "            kernel_size=(3, 3),    # height/width of filter\n",
    "            activation = 'relu',    # activation function \n",
    "            input_shape = (250, 300, 3))) # shape of input (image)\n",
    "\n",
    "cnn_model.add(MaxPooling2D\n",
    "             (pool_size=(2,2))) # dimensions of the region of pooling\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 128,\n",
    "                    kernel_size = (3,3),\n",
    "                    activation = 'relu'))\n",
    "\n",
    "cnn_model.add(MaxPooling2D\n",
    "             (pool_size=(2,2))) # dimensions of the region of pooling\n",
    "\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 64,\n",
    "                    kernel_size = (3,3),\n",
    "                    activation = 'relu'))\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 64,\n",
    "                    kernel_size = (3,3),\n",
    "                    activation = 'relu'))\n",
    "\n",
    "cnn_model.add(MaxPooling2D\n",
    "             (pool_size=(2,2))) # dimensions of the region of pooling\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "cnn_model.add(Dense(32, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "cnn_model.add(Dense(16, activation='relu'))\n",
    "\n",
    "cnn_model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 248, 298, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 124, 149, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 122, 147, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 61, 73, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 59, 71, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 57, 69, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 28, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 60928)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               7798912   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 8,071,681\n",
      "Trainable params: 8,071,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "cnn_model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3788/3788 [==============================] - 5358s 1s/step - loss: 44.6536 - mae: 0.1838\n",
      "Epoch 2/10\n",
      "3788/3788 [==============================] - 5052s 1s/step - loss: 4.8512e-07 - mae: 5.5409e-04\n",
      "Epoch 3/10\n",
      "3788/3788 [==============================] - 5036s 1s/step - loss: 1.7703e-08 - mae: 5.8933e-05\n",
      "Epoch 4/10\n",
      "3788/3788 [==============================] - 5087s 1s/step - loss: 1.3521e-11 - mae: 7.4376e-07\n",
      "Epoch 5/10\n",
      "3788/3788 [==============================] - 5083s 1s/step - loss: 1.8514e-14 - mae: 2.0649e-08\n",
      "Epoch 6/10\n",
      "3788/3788 [==============================] - 5106s 1s/step - loss: 1.4594e-23 - mae: 1.7060e-12\n",
      "Epoch 7/10\n",
      "3788/3788 [==============================] - 30477s 8s/step - loss: 7.1217e-10 - mae: 6.7091e-06\n",
      "Epoch 8/10\n",
      "3788/3788 [==============================] - 5075s 1s/step - loss: 7.3813e-10 - mae: 6.9565e-06\n",
      "Epoch 9/10\n",
      "3788/3788 [==============================] - 5110s 1s/step - loss: 7.8813e-10 - mae: 7.5446e-06\n",
      "Epoch 10/10\n",
      "3788/3788 [==============================] - 5159s 1s/step - loss: 8.3611e-10 - mae: 7.7194e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_len = train_df.shape[0]\n",
    "my_batch_size = 8\n",
    "\n",
    "history = cnn_model.fit_generator(image_batch_gen(train_df, my_batch_size, data_len),\n",
    "                                  steps_per_epoch=data_len//my_batch_size,\n",
    "                                  epochs=10,\n",
    "                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = PIL.Image.open(drawception.iloc[12345,15])\n",
    "testing = testing.reduce(4)\n",
    "#testing[1,:,:,:] = np.asarray(testing)\n",
    "my_image = np.empty((1, 125, 150, 3))\n",
    "my_image[0,:,:,:] = np.asarray(testing)\n",
    "\n",
    "my_image.shape\n",
    "#drawception.iloc[2375,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawception.iloc[12345,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.predict(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The iloc call is looking for img_path and is using 15 for that index right now\n",
    "def test_batch(dataframe, size):   \n",
    "    \n",
    "    image_batch = np.empty((size, 250, 300, 3))\n",
    "    for i in range(size):\n",
    "        my_image = PIL.Image.open(dataframe.iloc[i,15])\n",
    "        my_image = my_image.reduce(2)\n",
    "            \n",
    "        image_batch[i,:,:,:] = np.asarray(my_image)\n",
    "            \n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_batch(test_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 250, 300, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df['REACT'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8371321734390911"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.sort_values(by='REACT', ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(test_df[test_df.index == 17800]['img_path'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['preds'].plot(kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['REACT'].plot(kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(dataframe, model):   \n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    image_dat = np.empty((1, 250, 300, 3))\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        my_image = PIL.Image.open(dataframe.iloc[i,15])\n",
    "        my_image = my_image.reduce(2)\n",
    "            \n",
    "        image_dat[0,:,:,:] = np.asarray(my_image)\n",
    "        pred = model.predict(image_dat)\n",
    "        \n",
    "        img_dic = {}\n",
    "        img_dic['y_pred'] = pred.item()\n",
    "        img_dic['y_true'] = dataframe.iloc[i,14]\n",
    "        \n",
    "        output.append(img_dic)\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = predict_batch(test_df, cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7750"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7750, 16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.357639e-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.072601e-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.357639e-12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.551826e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.396612e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         y_pred  y_true\n",
       "0 -2.357639e-12       0\n",
       "1  1.072601e-02       0\n",
       "2 -2.357639e-12       1\n",
       "3 -5.551826e-03       1\n",
       "4 -5.396612e-01       1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(prediction_list)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_df['y_pred'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_df['y_true'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.664350530734745"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(pred_df['y_true'], pred_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
